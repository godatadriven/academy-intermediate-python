{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/pandas_pipelines/panda-paint.jpeg' width='200px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "# Modern Pipelines in pandas\n",
    "\n",
    "This notebook considers `pandas` in practice and how we can adopt great practice when working with data. \n",
    "\n",
    "Let's pretend that we've read in a timeseries and that this is the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.500065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>-0.439859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03 00:00:00</td>\n",
       "      <td>-0.133561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04 00:00:00</td>\n",
       "      <td>-0.090145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05 00:00:00</td>\n",
       "      <td>-0.583120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28 00:00:00</td>\n",
       "      <td>-1.260329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29 00:00:00</td>\n",
       "      <td>-0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30 00:00:00</td>\n",
       "      <td>-0.976887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>1.380869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.042389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date     value\n",
       "0    2018-01-01 00:00:00  0.500065\n",
       "1    2018-01-02 00:00:00 -0.439859\n",
       "2    2018-01-03 00:00:00 -0.133561\n",
       "3    2018-01-04 00:00:00 -0.090145\n",
       "4    2018-01-05 00:00:00 -0.583120\n",
       "..                   ...       ...\n",
       "361  2018-12-28 00:00:00 -1.260329\n",
       "362  2018-12-29 00:00:00 -0.022523\n",
       "363  2018-12-30 00:00:00 -0.976887\n",
       "364  2018-12-31 00:00:00  1.380869\n",
       "365  2019-01-01 00:00:00  0.042389\n",
       "\n",
       "[366 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_ts_df():\n",
    "    dates = [str(_) for _ in pd.date_range(\"2018-01-01\", \"2019-01-01\")]\n",
    "    values = [np.nan if np.random.random() < 0.05 else _ for _ in np.random.normal(0, 1, 366)]\n",
    "    return pd.DataFrame({\"date\": dates, \"value\": values})\n",
    "\n",
    "date_df = make_ts_df()\n",
    "date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start analysing the data, let's imagine we want to do the following:\n",
    "\n",
    "- Get rid of the redundant hours.\n",
    "- Clean the `nan` values.\n",
    "- Remove outliers. \n",
    "\n",
    "One way of doing it could be like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.500065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>-0.439859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.133561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>-0.090145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.583120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>-1.260329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>-0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>-0.976887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.380869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.042389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     value\n",
       "0   2018-01-01  0.500065\n",
       "1   2018-01-02 -0.439859\n",
       "2   2018-01-03 -0.133561\n",
       "3   2018-01-04 -0.090145\n",
       "4   2018-01-05 -0.583120\n",
       "..         ...       ...\n",
       "361 2018-12-28 -1.260329\n",
       "362 2018-12-29 -0.022523\n",
       "363 2018-12-30 -0.976887\n",
       "364 2018-12-31  1.380869\n",
       "365 2019-01-01  0.042389\n",
       "\n",
       "[333 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    date_df\n",
    "    .assign(date=lambda df: pd.to_datetime(df['date']).dt.normalize())\n",
    "    .dropna()\n",
    "    .loc[lambda df: df['value'] > -2.0]\n",
    "    .loc[lambda df: df['value'] < 2.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the way we've been doing it so far, but we can do better.\n",
    "\n",
    "If you were to just look at the code above it could be a bit hard to understand what is going on.\n",
    "\n",
    "Also, if we were to get a new date dataframe, we'd have to start all over again. \n",
    "\n",
    "Whilst this is not a big issue when we are only doing 3 processing steps, as the amount of processing increases it could become time consuming.\n",
    "\n",
    "## Pipeline abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.500065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>-0.439859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.133561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>-0.090145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.583120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>-1.260329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>-0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>-0.976887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.380869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.042389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     value\n",
       "0   2018-01-01  0.500065\n",
       "1   2018-01-02 -0.439859\n",
       "2   2018-01-03 -0.133561\n",
       "3   2018-01-04 -0.090145\n",
       "4   2018-01-05 -0.583120\n",
       "..         ...       ...\n",
       "361 2018-12-28 -1.260329\n",
       "362 2018-12-29 -0.022523\n",
       "363 2018-12-30 -0.976887\n",
       "364 2018-12-31  1.380869\n",
       "365 2019-01-01  0.042389\n",
       "\n",
       "[333 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_dates(dataf):\n",
    "    \"\"\"Removes the hours from dates\"\"\"\n",
    "    return (dataf\n",
    "            .assign(date=lambda d: pd.to_datetime(d['date']).dt.normalize()))\n",
    "\n",
    "def remove_nan_rows(dataf):\n",
    "    \"\"\"Removes rows with missing values\"\"\"\n",
    "    return (dataf.dropna())\n",
    "\n",
    "def fill_nan(dataf):\n",
    "    \"\"\"Replaces NaN values with 0\"\"\"\n",
    "    return (dataf.fillna(0))\n",
    "\n",
    "def remove_outliers(dataf):\n",
    "    \"\"\"Removes values less than -2 and greater than 2\"\"\"\n",
    "    return (dataf\n",
    "            .loc[lambda d: d['value'] > -2.0]\n",
    "            .loc[lambda d: d['value'] < 2.0])\n",
    "\n",
    "prep_df = (date_df\n",
    "           .pipe(parse_dates)\n",
    "           .pipe(remove_nan_rows)\n",
    "           .pipe(remove_outliers))\n",
    "prep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.500065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>-0.439859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.133561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>-0.090145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.583120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>-1.260329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>-0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>-0.976887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.380869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.042389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     value\n",
       "0   2018-01-01  0.500065\n",
       "1   2018-01-02 -0.439859\n",
       "2   2018-01-03 -0.133561\n",
       "3   2018-01-04 -0.090145\n",
       "4   2018-01-05 -0.583120\n",
       "..         ...       ...\n",
       "361 2018-12-28 -1.260329\n",
       "362 2018-12-29 -0.022523\n",
       "363 2018-12-30 -0.976887\n",
       "364 2018-12-31  1.380869\n",
       "365 2019-01-01  0.042389\n",
       "\n",
       "[333 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df = (\n",
    "    date_df\n",
    "   .pipe(parse_dates)\n",
    "   .pipe(remove_nan_rows)\n",
    "   .pipe(remove_outliers)\n",
    ")\n",
    "prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.pipe()` method allows us to pass a function that accepts a dataframe as it's first argument. This is a very nice flow. \n",
    "\n",
    "- We can easily use this pipeline (or parts of this pipeline) for different datasets.\n",
    "\n",
    "<img src='images/lego.png' width='400px'  style=\"padding: 15px\">\n",
    "\n",
    "- If there is ever a bug this pipeline will make it easier for us to figure out where it is. Since every step is merely a function, we'll know eactly where the process is breaking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can give the function a descriptive name and on a pipeline level this allows us to see \"what\" is happening \"when\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_dates in module __main__:\n",
      "\n",
      "parse_dates(dataf)\n",
      "    Removes the hours from dates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# e.g. You may not have seen how the parse_dates function works yet\n",
    "help(parse_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats \n",
    "\n",
    "We should be careful when we are writing `.pipe`-lines. The function going into a `.pipe()` might not be ***stateless***. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = make_ts_df() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(dataf):\n",
    "    dataf.columns = [\"a\", \"b\"]\n",
    "    return dataf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['a', 'b'], dtype='object'), Index(['a', 'b'], dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.pipe(rename_columns).columns, date_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such a situation it is best to include a `.copy()` command - or better - use a stateless method like `.rename()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recreate the random data\n",
    "date_df = make_ts_df()\n",
    "\n",
    "def rename_columns(dataf):\n",
    "    return dataf.rename(columns = {'date':'a','value':'b'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['a', 'b'], dtype='object'), Index(['date', 'value'], dtype='object'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.pipe(rename_columns).columns, date_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with this. We want our functions to be stateless, otherwise we might accidentally change the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline abstraction on higher Levels\n",
    "\n",
    "To fully appreciate what the pandas pipelines can do, let us rewrite one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.317229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1.146415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-1.441736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.130457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.208198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>0.381188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>-0.652311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>-0.254666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>0.727229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.550652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     value\n",
       "0   2018-01-01  1.317229\n",
       "1   2018-01-02  1.146415\n",
       "2   2018-01-03 -1.441736\n",
       "3   2018-01-04  0.130457\n",
       "4   2018-01-05 -0.208198\n",
       "..         ...       ...\n",
       "361 2018-12-28  0.381188\n",
       "362 2018-12-29 -0.652311\n",
       "363 2018-12-30 -0.254666\n",
       "364 2018-12-31  0.727229\n",
       "365 2019-01-01  0.550652\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_outliers(dataf, min_value=None, max_value=None):\n",
    "    \"\"\"Removes outliers less than min_value and greater than max_value\"\"\"\n",
    "    \n",
    "    if not (min_value and max_value):\n",
    "        raise ValueError('Hey silly, you need to state a min and max!')\n",
    "    \n",
    "    return (dataf\n",
    "            .loc[lambda d: d['value'] > min_value]\n",
    "            .loc[lambda d: d['value'] < max_value])\n",
    "\n",
    "(\n",
    "    date_df\n",
    "    .pipe(parse_dates)\n",
    "    .pipe(remove_nan_rows)\n",
    "    .pipe(remove_outliers, min_value=-2, max_value=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.pipe()` can accept keyword arguments. This allows you to change, say, threshold values on a high level. No need to change the original function, you can change things from a higher level. This is great because it will encourage you to write functions that are general. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Exercise</mark>\n",
    "\n",
    "Rewrite the following as a pandas pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-05-15 10:00:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>VIOLATION OF RESTRAINING ORDER</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>900 Block of PIERCE ST</td>\n",
       "      <td>-122.435080</td>\n",
       "      <td>37.778696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-13 01:00:00</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>LOST PROPERTY</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>11TH ST / MISSION ST</td>\n",
       "      <td>-122.417105</td>\n",
       "      <td>37.774324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-17 15:00:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT OF PROPERTY</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0 Block of THE EMBARCADERONORTH ST</td>\n",
       "      <td>-122.388380</td>\n",
       "      <td>37.783310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-05-04 12:00:00</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>AIDED CASE</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1200 Block of QUESADA AV</td>\n",
       "      <td>-122.383118</td>\n",
       "      <td>37.728547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-05 14:00:00</td>\n",
       "      <td>MISSING PERSON</td>\n",
       "      <td>MISSING JUVENILE</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>LOCATED</td>\n",
       "      <td>0 Block of BOWMAN CT</td>\n",
       "      <td>-122.382494</td>\n",
       "      <td>37.738047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                        Descript  \\\n",
       "0  2004-05-15 10:00:00  OTHER OFFENSES  VIOLATION OF RESTRAINING ORDER   \n",
       "1  2008-07-13 01:00:00    NON-CRIMINAL                   LOST PROPERTY   \n",
       "2  2010-07-17 15:00:00   LARCENY/THEFT         GRAND THEFT OF PROPERTY   \n",
       "3  2008-05-04 12:00:00    NON-CRIMINAL                      AIDED CASE   \n",
       "4  2004-08-05 14:00:00  MISSING PERSON                MISSING JUVENILE   \n",
       "\n",
       "  PdDistrict Resolution                             Address           X  \\\n",
       "0       PARK       NONE              900 Block of PIERCE ST -122.435080   \n",
       "1   SOUTHERN       NONE                11TH ST / MISSION ST -122.417105   \n",
       "2   SOUTHERN       NONE  0 Block of THE EMBARCADERONORTH ST -122.388380   \n",
       "3    BAYVIEW       NONE            1200 Block of QUESADA AV -122.383118   \n",
       "4    BAYVIEW    LOCATED                0 Block of BOWMAN CT -122.382494   \n",
       "\n",
       "           Y  \n",
       "0  37.778696  \n",
       "1  37.774324  \n",
       "2  37.783310  \n",
       "3  37.728547  \n",
       "4  37.738047  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanfran = pd.read_csv('data/san_fran_crime_sample.csv')\n",
    "sanfran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m (\n\u001b[32m      2\u001b[39m     \u001b[43msanfran\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdates\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2004\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2014\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mME\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_rolling\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCrime Count in San Fransisco\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/codespaces/academy-intermediate-python/venv/lib/python3.12/site-packages/pandas/plotting/_core.py:947\u001b[39m, in \u001b[36mPlotAccessor.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     plot_backend = \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     x, y, kind, kwargs = \u001b[38;5;28mself\u001b[39m._get_call_args(\n\u001b[32m    950\u001b[39m         plot_backend.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m._parent, args, kwargs\n\u001b[32m    951\u001b[39m     )\n\u001b[32m    953\u001b[39m     kind = \u001b[38;5;28mself\u001b[39m._kind_aliases.get(kind, kind)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/codespaces/academy-intermediate-python/venv/lib/python3.12/site-packages/pandas/plotting/_core.py:1944\u001b[39m, in \u001b[36m_get_plot_backend\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[32m-> \u001b[39m\u001b[32m1944\u001b[39m module = \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1945\u001b[39m _backends[backend_str] = module\n\u001b[32m   1946\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/codespaces/academy-intermediate-python/venv/lib/python3.12/site-packages/pandas/plotting/_core.py:1874\u001b[39m, in \u001b[36m_load_backend\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m   1872\u001b[39m         module = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mpandas.plotting._matplotlib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   1875\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmatplotlib is required for plotting when the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1876\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mdefault backend \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m is selected.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1877\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[32m   1880\u001b[39m found_backend = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "(\n",
    "    sanfran\n",
    "    .rename(columns=str.lower)\n",
    "    .rename(columns={'dates': 'date'})\n",
    "    .assign(date = lambda df: pd.to_datetime(df['date']).dt.normalize())\n",
    "    .set_index('date')\n",
    "    .sort_index()\n",
    "    .loc['2004':'2014']\n",
    "    .resample('ME')[['category']].count()\n",
    "    .assign(category_rolling = lambda df: df['category'].rolling(10).mean())\n",
    "    .plot(figsize=(9,5), title='Crime Count in San Fransisco')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/pandas_pipelines/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Bonus Exercise: Add a decorator<mark>\n",
    "\n",
    "Familiar with decorators? Add a decorator to log:\n",
    "    \n",
    "- the shape of the dataframe before and after (see decorator `log_shape`)\n",
    "- the time it takes to run the function (create a decorator called `log_time`)\n",
    "    \n",
    "We can add a little more power here and add some logging functionality with **a decorator**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: See below for example with decorators on the dataframe `date_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "\n",
    "def log_shape(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        shape_before = args[0].shape\n",
    "        shape_after = result.shape\n",
    "        print(f\"{func.__name__} => before shape:{shape_before} after shape:{shape_after}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_shape\n",
    "def parse_dates(dataf):\n",
    "    return (dataf\n",
    "            .assign(date=lambda d: pd.to_datetime(d.date)))\n",
    "\n",
    "@log_shape\n",
    "def remove_nan_rows(dataf):\n",
    "    return (dataf.dropna())\n",
    "\n",
    "@log_shape\n",
    "def remove_outliers(dataf, min_val=-2.0, max_val=2.0):\n",
    "    return (dataf\n",
    "            .loc[lambda d: d['value'] > min_val]\n",
    "            .loc[lambda d: d['value'] < max_val])\n",
    "\n",
    "prep_df = (date_df\n",
    "           .pipe(parse_dates)\n",
    "           .pipe(remove_nan_rows)\n",
    "           .pipe(remove_outliers, min_val=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/pandas_pipelines/pipeline-decorator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the benefit of having a standard decorator that can log pandas steps: \n",
    "\n",
    "1. When writing code, this might help you in discovering what is happening. If you see rows dissapear while they shouldn't this log might give you a proxy. \n",
    "2. When this pandas code goes to production you will have some logging for free in airflow. If something goes wrong there you may also be able to debug more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "> **\"Pipelines are the only correct way to write pandas.\"**\n",
    "\n",
    "This is a bold statement, but some of people very strongly about this. \n",
    "\n",
    "Even if you take this statement with a grain of salt, it is important to write your code in such a way that your notebooks remains clear - if it takes a lot of effort to understand the code of your colleagues, then your team will be slower than you want it to be. \n",
    "\n",
    "A notebook is a great scratchpad, but that is no excuse to write unclear code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
